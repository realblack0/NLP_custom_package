{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from nltk import word_tokenize\n",
    "from math import log, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF variants: https://en.wikipedia.org/wiki/Tf–idf\n",
    "def tf1(frequency, N, maxTf, k): return 1 if frequency else 0 # binary \n",
    "def tf2(frequency, N, maxTf, k): return frequency # raw count\n",
    "def tf3(frequency, N, maxTf, k): return frequency / N # term frequency\n",
    "def tf4(frequency, N, maxTf, k): return log(1 + frequency) # log normalization\n",
    "def tf6(frequency, N, maxTf, k): return k+(1-k)*(frequency/maxTf) # double normalization k\n",
    "def tf5(frequency, N, maxTf, k): return tf6(frequency, maxTf, 0.5) # double normaliztion 0.5\n",
    "\n",
    "tfSet = [tf1, tf2, tf3, tf4, tf5, tf6]\n",
    "\n",
    "def idf1(df, N): return 1 # unary\n",
    "def idf2(df, N): return log(N/df) # inverse document frequency\n",
    "def idf3(df, N): return log(N/(1+df)) # inverse document frequency smooth\n",
    "# idf4 = lambda df, N, maxDf: log(maxDf/(1+df)) # inverse document frequency max\n",
    "def idf5(df, N): return log((N-df)/df) # probabilistic inverse document frequency\n",
    "\n",
    "idfSet = [idf1, idf2, idf3, None, idf5]\n",
    "\n",
    "distance = lambda x1, x2: (x1-x2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN_Classifier:\n",
    "    def __init__(self, tokenizer=None, tf=6, idf=2):\n",
    "        tokenizer = tokenizer if not tokenizer == None else word_tokenize\n",
    "        self.params = {\"tokenizer\":tokenizer, \n",
    "                       \"tf\":tfSet[tf-1], \n",
    "                       \"idf\":idfSet[idf-1]}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"doc string\"\"\"\n",
    "        # check valid dataset\n",
    "        assert len(X) == len(y)\n",
    "        \n",
    "        # define objects\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes = list(set(y))\n",
    "        self.doc2idx = lambda d: X.index(d)\n",
    "        self.idx2doc = lambda i: X[i]\n",
    "        \n",
    "        self.vocabulary = list()\n",
    "        self._posting = list()\n",
    "        self._lexicon = defaultdict(lambda :-1)\n",
    "        self._docInfo = defaultdict(lambda: {\"maxTf\":0, \"vecLen\":0.0})\n",
    "        self._weights = []\n",
    "        self._wLexicon = defaultdict(lambda:{\"wptr\":-1, \"df\":0})\n",
    "\n",
    "        # TDM\n",
    "        for doc in X:\n",
    "            docID = self.doc2idx(doc)\n",
    "            localPosting = defaultdict(int)\n",
    "            for token in self.params[\"tokenizer\"](doc):\n",
    "                if token not in self.vocabulary:\n",
    "                    self.vocabulary.append(token)\n",
    "                localPosting[token] += 1\n",
    "                \n",
    "            maxTf = max(localPosting.values())\n",
    "            self._docInfo[docID][\"maxTf\"] = maxTf\n",
    "            \n",
    "            for token, freq in localPosting.items():\n",
    "                ptr = self._lexicon[token]\n",
    "                nextPtr = len(self._posting)\n",
    "                self._posting.append((docID, freq, ptr))\n",
    "                self._lexicon[token] = nextPtr\n",
    "                self._wLexicon[token][\"df\"] += 1\n",
    "        \n",
    "        # weight        \n",
    "        N = len(X)\n",
    "        for token in self.vocabulary:\n",
    "            ptr = self._lexicon[token]\n",
    "            self._wLexicon[token][\"wptr\"] = len(self._weights)\n",
    "            while ptr != -1:\n",
    "                _struct = self._posting[ptr]\n",
    "                weight = self.params[\"tf\"](_struct[1], N, \n",
    "                           self._docInfo[_struct[0]][\"maxTf\"], 0) * \\\n",
    "                         self.params[\"idf\"](self._wLexicon[token][\"df\"], N)\n",
    "                self._weights.append((_struct[0], weight))\n",
    "                self._docInfo[_struct[0]][\"vecLen\"] += \\\n",
    "                                            distance(0,weight)**2\n",
    "                ptr = _struct[-1]\n",
    "        \n",
    "        \n",
    "    def refit(tf, idf):\n",
    "        \"\"\"doc string\"\"\"\n",
    "        self.params[\"tf\"] = tfSet[tf-1]\n",
    "        self.params[\"idf\"] = idfset[idf-1]\n",
    "        \n",
    "        # weight        \n",
    "        N = len(X)\n",
    "        for token in self.vocabulary:\n",
    "            ptr = self._lexicon[token]\n",
    "            self._wLexicon[token][\"wptr\"] = len(self._weights)\n",
    "            while ptr != -1:\n",
    "                _struct = self._posting[ptr]\n",
    "                weight = self.params[\"tf\"](_struct[1], N, \n",
    "                           self._docInfo[_struct[0]][\"maxTf\"], 0) * \\\n",
    "                         self.params[\"idf\"](df, N)\n",
    "                self._weights.append((_struct[-1], weight))\n",
    "                self._docInfo[_struct[-1]][\"vecLen\"] += \\\n",
    "                                            distance(0,weight)**2\n",
    "                ptr = _struct[-1]\n",
    "        \n",
    "        \n",
    "    def predict_prob(self, test, *, k=5, method=\"cosine\"):\n",
    "        \"\"\"doc string\"\"\"\n",
    "        assert method in [\"euclide\", \"cosine\"], \"Invalid method\"\n",
    "        \n",
    "        # test indexing\n",
    "        qRepr = defaultdict(int)\n",
    "        qWeight = defaultdict(float)\n",
    "        qVecLen = 0.0\n",
    "        for token in self.params[\"tokenizer\"](test):\n",
    "            if token in self.vocabulary:\n",
    "                qRepr[token] += 1\n",
    "        maxQtf = max(qRepr.values())\n",
    "        \n",
    "        # test weight\n",
    "        N = len(self.X)\n",
    "        for token, freq in qRepr.items():\n",
    "            qWeight[token] = self.params[\"tf\"](freq, N, maxQtf, 0) *\\\n",
    "                             self.params[\"idf\"](\n",
    "                                        self._wLexicon[token][\"df\"], N)\n",
    "            qVecLen += distance(0, qWeight[token])**2\n",
    "            \n",
    "        # find neighbors\n",
    "        if method == \"euclide\":\n",
    "            result = defaultdict(float)\n",
    "            for token, _wptr_df in self._wLexicon.items():\n",
    "                wptr = _wptr_df[\"wptr\"]\n",
    "                df = _wptr_df[\"df\"]\n",
    "                for _ in range(df):\n",
    "                    _struct = self._weights[wptr]\n",
    "                    result[_struct[0]] += distance(_struct[-1],\n",
    "                                                    qWeight[token])\n",
    "                    wptr += 1\n",
    "            result = {self.y[docID]:sqrt(v) for docID, v in result.items()}\n",
    "            return sorted(result.items(), \n",
    "                          key=lambda x:x[1], reverse=True)[:k]\n",
    "        \n",
    "        elif method == \"cosine\":\n",
    "            result = defaultdict(float)\n",
    "            for token, _wptr_df in self._wLexicon.items():\n",
    "                wptr = _wptr_df[\"wptr\"]\n",
    "                df = _wptr_df[\"df\"]\n",
    "                for _ in range(df):\n",
    "                    _struct = self._weights[wptr]\n",
    "                    result[_struct[0]] += _struct[-1] *\\\n",
    "                                                    qWeight[token]\n",
    "                    wptr += 1\n",
    "            result = [\n",
    "                (self.y[docID], v/(sqrt(qVecLen) * sqrt(self._docInfo[docID][\"vecLen\"])))\n",
    "                for docID, v in result.items()\n",
    "            ]\n",
    "            return sorted(result, \n",
    "                          key=lambda x:x[1], reverse=True)[:k]\n",
    "    \n",
    "    \n",
    "    def predict(self, test, *, k=5, method=\"cosine\"):\n",
    "        \"\"\"doc string\"\"\"\n",
    "        assert method in [\"euclide\", \"cosine\"], \"Invalid method\"\n",
    "        assert isinstance(test, str)\n",
    "        # predict\n",
    "        result = self.predict_prob(test, k=k, method=method)    \n",
    "        k_class_count = Counter([_[0] for _ in result]).most_common()\n",
    "        k_most_freqeunt = k_class_count[0][0]\n",
    "        candidates = [_[0] for _ in k_class_count if _[0] == k_most_freqeunt]\n",
    "        # sorting\n",
    "        if len(candidates) == 1:\n",
    "            return candidates[0]\n",
    "        else:\n",
    "            for cand, prob in result:\n",
    "                if cand in candidates:\n",
    "                    return cand\n",
    "        \n",
    "    def predict_many(self, testset, k=5, method=\"cosine\"):\n",
    "        from collections import Container\n",
    "        assert issubclass(type(testset), Container)\n",
    "        \n",
    "        result = []\n",
    "        for test in testset:\n",
    "            result.append(self.predict(test, k=k, method=method))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "basedir = \"C:/Users/JINHYO/1. My Training/IPA NLP Class/1.수업/NLP_Class/practice/8일차_실습_project/헤드라인/\"\n",
    "Class = [\"IT 과학\", \"경제\", \"사회\", \"생활 문화\", \"정치\"]\n",
    "fileList = [_ for _ in os.listdir(basedir) if 10 < len(_)]\n",
    "train_X = []\n",
    "train_y = []\n",
    "for c in Class:\n",
    "    for file in [basedir + _ for _ in fileList if _.startswith(c+\"-\")]:\n",
    "        train_X.append(open(file, encoding=\"utf-8\").read())\n",
    "        train_y.append(c)\n",
    "        \n",
    "test_X = []\n",
    "test_y = []\n",
    "for filename in os.listdir(\"C:/Users/JINHYO/1. My Training/IPA NLP Class/1.수업/NLP_Class/practice/testData\"):\n",
    "    if not filename.startswith(\"세계\"):\n",
    "        test_X.append(open(\"C:/Users/JINHYO/1. My Training/IPA NLP Class/1.수업/NLP_Class/practice/testData/\" + filename, encoding=\"utf-8\").read())\n",
    "        testcls = filename.split(\"-\")[0].replace(\"&\", \" \")\n",
    "        test_y.append(testcls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = kNN_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('생활 문화', 0.20858041472462496),\n",
       " ('경제', 0.163400543332466),\n",
       " ('경제', 0.10947826737509088),\n",
       " ('생활 문화', 0.09904514223272988),\n",
       " ('사회', 0.09809072927475788)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_prob(test_X[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('사회', 4.338281692521411),\n",
       " ('경제', 4.327098108728728),\n",
       " ('정치', 4.290565724481992),\n",
       " ('생활 문화', 4.154136172981419),\n",
       " ('IT 과학', 4.114677442426481)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_prob(test_X[19], method=\"euclide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'생활 문화'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(test_X[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사회'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(test_X[19], method=\"euclide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JINHYO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:155: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT 과학       1.00      0.10      0.18        10\n",
      "          경제       0.33      0.30      0.32        10\n",
      "          사회       0.45      0.50      0.48        10\n",
      "       생활 문화       1.00      0.80      0.89        10\n",
      "          정치       0.43      0.90      0.58        10\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.64      0.52      0.49        50\n",
      "weighted avg       0.64      0.52      0.49        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicts = knn.predict_many(test_X, k=20)\n",
    "print(classification_report(test_y, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT 과학       0.00      0.00      0.00        10\n",
      "          경제       0.15      0.40      0.22        10\n",
      "          사회       0.33      0.40      0.36        10\n",
      "       생활 문화       0.00      0.00      0.00        10\n",
      "          정치       0.30      0.30      0.30        10\n",
      "\n",
      "    accuracy                           0.22        50\n",
      "   macro avg       0.16      0.22      0.18        50\n",
      "weighted avg       0.16      0.22      0.18        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JINHYO\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predicts = knn.predict_many(test_X, method=\"euclide\", k=20)\n",
    "print(classification_report(test_y, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
